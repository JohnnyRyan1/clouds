{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5150c171-9f78-449c-b434-7fa2025765f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "DESCRIPTION\n",
    "\n",
    "Compute MODIS cloud fraction for one year.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import netCDF4\n",
    "import pyresample\n",
    "from scipy.interpolate import griddata\n",
    "from pyhdf.SD import SD, SDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "304eca69-bd4b-4f88-bf45-f68826af27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function\n",
    "def sds_read(dataset, variable):\n",
    "    \n",
    "    # Read SDS\n",
    "    sds = dataset.select(variable) \n",
    "    sds_scale = sds.attributes()['scale_factor']\n",
    "    sds_offset = sds.attributes()['add_offset']\n",
    "    \n",
    "    mask = (sds.get() == sds.attributes()['_FillValue'])\n",
    "    sds_float = sds.get().astype('float')\n",
    "    sds_float[mask] = np.nan\n",
    "    \n",
    "    return (sds_float - sds_offset) * sds_scale\n",
    "\n",
    "    \n",
    "def MYD06_L2_Read(myd, attribute):\n",
    "    \n",
    "    # Read MODIS file\n",
    "    f = SD(myd, SDC.READ)\n",
    "    \n",
    "    # Get datasets\n",
    "    sds_lat = f.select('Latitude')\n",
    "    latitude = sds_lat.get()\n",
    "    \n",
    "    sds_lon = f.select('Longitude')\n",
    "    longitude = sds_lon.get()\n",
    "    \n",
    "    att = sds_read(f, attribute)\n",
    "    \n",
    "    # Interpolate some attributes from 5 km to 1 km    \n",
    "    grid_x_1km, grid_y_1km = np.meshgrid(np.linspace(0, latitude.shape[1]-1, att.shape[1]), \n",
    "                                 np.linspace(0, latitude.shape[0]-1, att.shape[0]))\n",
    "    \n",
    "    grid_x_5km, grid_y_5km = np.meshgrid(np.arange(0, latitude.shape[1], 1), \n",
    "                                 np.arange(0, latitude.shape[0], 1))\n",
    "    \n",
    "    latitude_1km = griddata((np.ravel(grid_x_5km), np.ravel(grid_y_5km)), \n",
    "                       np.ravel(latitude), (grid_x_1km, grid_y_1km), \n",
    "                       method='linear')\n",
    "    longitude_1km = griddata((np.ravel(grid_x_5km), np.ravel(grid_y_5km)), \n",
    "                       np.ravel(longitude), (grid_x_1km, grid_y_1km), \n",
    "                       method='linear')\n",
    "    \n",
    "    data = np.dstack((latitude_1km[50:-50, 50:-50], longitude_1km[50:-50, 50:-50], \n",
    "                  att[50:-50, 50:-50]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cca788e7-0886-4917-910a-ba28929cc902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "path = '/Users/jryan4/Dropbox (University of Oregon)/research/clouds/data/'\n",
    "\n",
    "# Define files\n",
    "modis_list = sorted(glob.glob('/Volumes/Extreme Pro/clouds/*.hdf'))\n",
    "\n",
    "# Define destination for predicted data\n",
    "dest = path + 'modis_cloud_properties/'\n",
    "\n",
    "# Define ice sheet grid\n",
    "ismip = netCDF4.Dataset(path + 'masks/1km-ISMIP6.nc')\n",
    "ismip_lon = ismip.variables['lon'][:]\n",
    "ismip_lat = ismip.variables['lat'][:]\n",
    "\n",
    "# Define years\n",
    "years = np.arange(2003, 2021, 1)\n",
    "\n",
    "# Define good hours\n",
    "good_hours = ['06', '07', '08', '09', '10', '11', '12', '13', '14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "578d4064-845d-4806-b15b-548d706862ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_files = []\n",
    "for file in modis_list:\n",
    "    # Get path and filename seperately \n",
    "    infilepath, infilename = os.path.split(file)\n",
    "    # Get file name without extension            \n",
    "    infilehortname, extension = os.path.splitext(infilename)\n",
    "    \n",
    "    # Append hour\n",
    "    hour = infilehortname[18:20]\n",
    "    if hour in good_hours:\n",
    "        good_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63d266-7fe5-4719-b8a8-eda3baa020dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of files to chunk\n",
    "number = 50\n",
    "\n",
    "# Chunk into groups of 50\n",
    "bounds = np.arange(0, len(good_files), number)\n",
    "\n",
    "for bound in bounds:\n",
    "\n",
    "    # Get slice of list\n",
    "    files_sliced = good_files[bound:bound+number]\n",
    "\n",
    "    data_stacked = np.zeros((2881, 1681))\n",
    "    for i in range(len(files_sliced)):\n",
    "        print('Processing... %.0f out of %.0f' %(i+1, len(files_sliced)))\n",
    "\n",
    "        # Read HDF\n",
    "        data = MYD06_L2_Read(files_sliced[i], 'Cloud_Phase_Optical_Properties')\n",
    "\n",
    "        # Set zeros to NaNs\n",
    "        data[:,:,2][data[:,:,2] == 0] = np.nan\n",
    "\n",
    "        # Convert liquid , ice, and undetermined flags to 2\n",
    "        data[:,:,2][data[:,:,2] > 1] = 2\n",
    "\n",
    "        # 2 = CTH, 3 = CTT, 4 = CTP, 5 = PHASE, 6 = COT, 7 = CER, 8 = CWP\n",
    "        if np.nansum(np.isfinite(data[:,:,2])) > 200000:\n",
    "            # Resample radiative fluxes to ISMIP grid\n",
    "            swath_def = pyresample.geometry.SwathDefinition(lons=data[:,:,1], lats=data[:,:,0])\n",
    "            swath_con = pyresample.geometry.GridDefinition(lons=ismip_lon, lats=ismip_lat)\n",
    "\n",
    "\n",
    "            # Determine nearest (w.r.t. great circle distance) neighbour in the grid.\n",
    "            data_resampled = pyresample.kd_tree.resample_nearest(source_geo_def=swath_def, \n",
    "                                                             target_geo_def=swath_con, \n",
    "                                                             data=data[:,:,2],\n",
    "                                                             radius_of_influence=5000)\n",
    "\n",
    "            # Set zeros to NaNs\n",
    "            data_resampled[data_resampled == 0] = np.nan\n",
    "\n",
    "            # Stack\n",
    "            data_stacked = np.dstack((data_stacked, data_resampled))\n",
    "\n",
    "    # Remove first layer\n",
    "    data_stacked = data_stacked[:, :, 1:]\n",
    "\n",
    "    # Convert values\n",
    "    data_stacked[data_stacked == 1] = 0\n",
    "    data_stacked[data_stacked == 2] = 1\n",
    "\n",
    "    # Average\n",
    "    data_mean = np.nanmean(data_stacked, axis=2)\n",
    "\n",
    "    ###############################################################################\n",
    "    # Save 1 km dataset to NetCDF\n",
    "    ###############################################################################\n",
    "    dataset = netCDF4.Dataset(dest + 'myd06_cloud_' + str(bound) + '_' + str(bound+number) + '.nc', \n",
    "                              'w', format='NETCDF4_CLASSIC')\n",
    "    print('Creating... %s' % dest + 'myd06_cloud_' + str(bound) + '_' + str(bound+number)  + '.nc')\n",
    "    dataset.Title = \"Cloud fraction\"\n",
    "    import time\n",
    "    dataset.History = \"Created \" + time.ctime(time.time())\n",
    "    dataset.Projection = \"WGS 84\"\n",
    "    dataset.Reference = \"Ryan, J. C., Smith, L. C., et al. (unpublished)\"\n",
    "    dataset.Contact = \"jryan4@uoregon.edu\"\n",
    "\n",
    "    # Create new dimensions\n",
    "    lat_dim = dataset.createDimension('y', ismip_lat.shape[0])\n",
    "    lon_dim = dataset.createDimension('x', ismip_lat.shape[1])\n",
    "\n",
    "    # Define variable types\n",
    "    Y = dataset.createVariable('latitude', np.float32, ('y','x'))\n",
    "    X = dataset.createVariable('longitude', np.float32, ('y','x'))\n",
    "\n",
    "    y = dataset.createVariable('y', np.float32, ('y'))\n",
    "    x = dataset.createVariable('x', np.float32, ('x'))\n",
    "\n",
    "\n",
    "    # Define units\n",
    "    Y.units = \"degrees\"\n",
    "    X.units = \"degrees\"\n",
    "\n",
    "    # Create the actual 3D variable\n",
    "    cloud_fraction_nc = dataset.createVariable('cloud_fraction', np.float32, ('y','x'))\n",
    "\n",
    "    # Write data to layers\n",
    "    Y[:] = ismip_lat\n",
    "    X[:] = ismip_lon\n",
    "    x[:] = ismip_lon[0,:]\n",
    "    y[:] = ismip_lat[:,0]\n",
    "    cloud_fraction_nc[:] = data_mean\n",
    "\n",
    "    print('Writing data to %s' % dest + 'myd06_cloud_' + str(bound) + '_' + str(bound+number) + '.nc')\n",
    "\n",
    "    # Close dataset\n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7ee8e-5b7b-4bc4-92e5-8dc7381d8266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
